{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leyKrIZvVDTY"
   },
   "source": [
    "**TP1 -Analyse vidéo**\n",
    "\n",
    "Benzaied Saifeddine -RT5 groupe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dVBolzwVGOJ"
   },
   "source": [
    "I. Acquisition Chargement et Sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ezt6_zoOUxHg",
    "outputId": "6d8627b5-b200-4efb-a35e-008b0e791a62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vidéo chargée avec succès\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Chargement de la vidéo\n",
    "video = cv2.VideoCapture(\"my_video_TPsAV.mp4\")\n",
    "\n",
    "# Vérification si la vidéo a bien été chargée\n",
    "if not video.isOpened():\n",
    "    print(\"Erreur lors de l'ouverture de la vidéo\")\n",
    "else:\n",
    "    print(\"Vidéo chargée avec succès\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3YeBHe4VdWD",
    "outputId": "7a2bd591-a7f3-4de2-ee4b-eed73c8f3d66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hauteur: 720, Largeur: 1280, FPS: 15, Nombre de frames: 164\n"
     ]
    }
   ],
   "source": [
    "# Récupérer les informations de la vidéo\n",
    "hauteur = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "largeur = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Hauteur: {hauteur}, Largeur: {largeur}, FPS: {fps}, Nombre de frames: {total_frames}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7CKIN1pVoh7",
    "outputId": "6ee13226-6f15-4c09-a008-82bbbfaa1637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegarde de frame_0.png\n",
      "Sauvegarde de frame_30.png\n",
      "Sauvegarde de frame_60.png\n",
      "Sauvegarde de frame_90.png\n",
      "Sauvegarde de frame_120.png\n",
      "Sauvegarde de frame_150.png\n"
     ]
    }
   ],
   "source": [
    "nbFrame = 0\n",
    "while True:\n",
    "    ret, frame = video.read()  # Lire la prochaine frame\n",
    "    if not ret:\n",
    "        break  # Si aucune frame n'est retournée, on sort de la boucle\n",
    "\n",
    "    if nbFrame % 30 == 0:  # Sauvegarde de chaque 30 frame\n",
    "        frame_name = f\"frame_{nbFrame}.png\"\n",
    "        cv2.imwrite(frame_name, frame)  # Sauvegarde de la frame dans un fichier image\n",
    "        print(f\"Sauvegarde de {frame_name}\")\n",
    "\n",
    "    nbFrame += 1\n",
    "    \n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OqQOQ6UbVwho",
    "outputId": "68a1a437-c2c5-42e0-da02-1bdf81946a07"
   },
   "outputs": [],
   "source": [
    "# Chargement de la vidéo\n",
    "video = cv2.VideoCapture(\"my_video_TPsAV.mp4\")\n",
    "\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Fermer toutes les fenêtres\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Tg6MAVVZVxQv"
   },
   "outputs": [],
   "source": [
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhYrEtMzl2Y-"
   },
   "source": [
    "II. Segmentation spatiale: Conversion et seuillage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "36e8LKQDl5GT",
    "outputId": "51d6bd89-1a94-4f25-99d5-de83c0029997"
   },
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"my_video_TPsAV.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Conversion en niveaux de gris\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Afficher l'image en niveaux de gris\n",
    "    cv2.imshow(\"Gray Frame\", gray_frame)\n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "16wqvXgLl78D",
    "outputId": "61913608-50e0-4bce-a6a4-54b833619617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de frames : 164\n",
      "Seuil final:  116.76290688326392\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def seuillage_heuristique(gray_frame, T_initial):\n",
    "    T = T_initial\n",
    "    while True:\n",
    "        # Segmentation avec le seuil actuel\n",
    "        _, img_seuil = cv2.threshold(gray_frame, T, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Pixels plus clairs que le seuil\n",
    "        above_T = gray_frame[gray_frame > T]\n",
    "        # Pixels plus sombres ou égaux au seuil\n",
    "        below_T = gray_frame[gray_frame <= T]\n",
    "\n",
    "        # Calcul de la nouvelle valeur du seuil avec vérification pour éviter les tranches vides\n",
    "        mean_above_T = above_T.mean() if above_T.size > 0 else T\n",
    "        mean_below_T = below_T.mean() if below_T.size > 0 else T\n",
    "\n",
    "        T_new = (mean_above_T + mean_below_T) / 2\n",
    "\n",
    "        if abs(T - T_new) < 1:  # Convergence\n",
    "            break\n",
    "        T = T_new\n",
    "\n",
    "    return img_seuil, T\n",
    "\n",
    "video = cv2.VideoCapture(\"my_video_TPsAV.mp4\")\n",
    "\n",
    "# Obtenir le nombre total de frames dans la vidéo\n",
    "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"Nombre total de frames : {total_frames}\")\n",
    "\n",
    "middle_frame_idx = total_frames // 2\n",
    "\n",
    "# Se positionner à la frame du milieu\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, middle_frame_idx)\n",
    "\n",
    "# Lire la frame\n",
    "ret, frame = video.read()\n",
    "\n",
    "if ret:\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Appliquer le seuillage\n",
    "    img_seuil, T_final = seuillage_heuristique(gray_frame, 150)\n",
    "\n",
    "    cv2.imshow(\"Image suillée\", img_seuil)\n",
    "    print(\"Seuil final: \",T_final)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Erreur lors du chargement de la vidéo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WlVcKLCwmAUx",
    "outputId": "905067e4-0c5d-4109-bc4f-b912bbe10252"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Appliquer le seuillage d'Otsu\n",
    "    _, img_otsu = cv2.threshold(gray_frame, 50, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Afficher la vidéo d'origine et la vidéo segmentée\n",
    "    cv2.imshow(\"Original Video\", frame)\n",
    "    cv2.imshow(\"Otsu Segmented Video\", img_otsu)\n",
    "\n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0Eh61MhmEtx"
   },
   "source": [
    "III. Segmentation temporelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eFfh3-r6mE-s",
    "outputId": "2c2f414c-541c-4391-d40d-327a99810b49"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Charger la vidéo\n",
    "video = cv2.VideoCapture('my_video_TPsAV.mp4')\n",
    "\n",
    "# Initialiser la première frame comme image de fond\n",
    "ret, frame_prev = video.read()\n",
    "frame_prev_gray = cv2.cvtColor(frame_prev, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convertir la frame actuelle en niveaux de gris\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Soustraction de l'image précédente\n",
    "    diff = cv2.absdiff(frame_gray, frame_prev_gray)\n",
    "\n",
    "    # Seuillage\n",
    "    _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Afficher la différence et l'image seuillée\n",
    "    cv2.imshow(\"Frame Actuelle\", frame)\n",
    "    cv2.imshow(\"Soustraction d images\", diff)\n",
    "    cv2.imshow(\"Seuillage\", thresh)\n",
    "\n",
    "    # Mettre à jour la frame précédente\n",
    "    frame_prev_gray = frame_gray\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrez la position de la frame à afficher (entre 0 et 163): 100\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Charger la vidéo\n",
    "video = cv2.VideoCapture('my_video_TPsAV.mp4')\n",
    "\n",
    "# Nombre total de frames dans la vidéo\n",
    "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Demander à l'utilisateur de choisir la position de la frame\n",
    "frame_position = int(input(f\"Entrez la position de la frame à afficher (entre 0 et {total_frames-1}): \"))\n",
    "\n",
    "# Se déplacer jusqu'à la frame choisie\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, frame_position)\n",
    "\n",
    "# Lire la frame choisie et la frame précédente pour la soustraction\n",
    "ret, frame_prev = video.read()\n",
    "frame_prev_gray = cv2.cvtColor(frame_prev, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Lire la frame actuelle (celle que l'on veut afficher)\n",
    "ret, frame = video.read()\n",
    "if ret:\n",
    "    # Convertir la frame actuelle en niveaux de gris\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Soustraction de la frame précédente\n",
    "    diff = cv2.absdiff(frame_gray, frame_prev_gray)\n",
    "\n",
    "    # Appliquer le seuillage\n",
    "    _, thresh = cv2.threshold(diff, 20, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Afficher les résultats\n",
    "    cv2.imshow(\"Frame Originale\", frame)  # Frame originale\n",
    "    cv2.imshow(\"Soustraction\", diff)      # Résultat de la soustraction\n",
    "    cv2.imshow(\"Seuillage\", thresh)       # Résultat du seuillage\n",
    "\n",
    "    # Attendre jusqu'à ce que l'utilisateur appuie sur une touche pour fermer les fenêtres\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "# Libérer la vidéo et fermer toutes les fenêtres\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0Pj4aMVgmKCl",
    "outputId": "114bcbe1-f1b8-4525-c00d-44df85685df7"
   },
   "outputs": [],
   "source": [
    "# Charger la vidéo\n",
    "video = cv2.VideoCapture('my_video_TPsAV.mp4')\n",
    "\n",
    "# Choix de N (décalage de N frames)\n",
    "N = 5\n",
    "\n",
    "# Lire les frames initiales pour la comparaison\n",
    "ret, frame_prev = video.read()\n",
    "for i in range(N):  # Sauter N frames avant de lire la frame actuelle\n",
    "    ret, frame_curr = video.read()\n",
    "ret, frame_next = video.read()\n",
    "\n",
    "while True:\n",
    "    # Convertir les frames en niveaux de gris\n",
    "    prev_gray = cv2.cvtColor(frame_prev, cv2.COLOR_BGR2GRAY)\n",
    "    curr_gray = cv2.cvtColor(frame_curr, cv2.COLOR_BGR2GRAY)\n",
    "    next_gray = cv2.cvtColor(frame_next, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calcul des différences entre la frame actuelle et la frame décalée de N frames\n",
    "    diff1 = cv2.absdiff(prev_gray, curr_gray)\n",
    "    diff2 = cv2.absdiff(curr_gray, next_gray)\n",
    "\n",
    "    # Opération OR pour combiner les zones de mouvement\n",
    "    motion = cv2.bitwise_or(diff1, diff2)\n",
    "\n",
    "    # Appliquer un flou pour réduire le bruit\n",
    "    motion_blur = cv2.GaussianBlur(motion, (5, 5), 0)\n",
    "\n",
    "    # Appliquer le seuillage\n",
    "    _, motion_thresh = cv2.threshold(motion_blur, 20, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Afficher le résultat\n",
    "    cv2.imshow(\"Détection de mouvement\", motion_thresh)\n",
    "\n",
    "    # Lire la prochaine frame et mettre à jour, sauter N frames pour la comparaison\n",
    "    frame_prev = frame_curr\n",
    "    for i in range(N):  # Sauter N frames pour la comparaison suivante\n",
    "        ret, frame_curr = video.read()\n",
    "    ret, frame_next = video.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "66mukVcRmMVU",
    "outputId": "8053269a-e35c-4235-ec36-cd949f464c43"
   },
   "outputs": [],
   "source": [
    "alpha = 0.45\n",
    "\n",
    "# Charger la vidéo\n",
    "video = cv2.VideoCapture('my_video_TPsAV.mp4')\n",
    "\n",
    "# Lire la première frame pour initialiser l'image de fond\n",
    "ret, frame = video.read()\n",
    "background = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convertir la frame actuelle en niveaux de gris\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculer la différence absolue\n",
    "    diff = cv2.absdiff(background.astype(np.uint8), gray)\n",
    "\n",
    "    # Seuillage\n",
    "    _, motion_mask = cv2.threshold(diff, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Afficher la détection de mouvement\n",
    "    cv2.imshow(\"Détection de mouvement\", motion_mask)\n",
    "\n",
    "    # Mise à jour du fond avec la méthode Adaptive Background Subtraction\n",
    "    background = alpha * gray + (1 - alpha) * background\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "clOHl_uYmOqo",
    "outputId": "bbef7e88-04d7-4db1-d8a0-dfd89a8b9829"
   },
   "outputs": [],
   "source": [
    "# Charger la vidéo\n",
    "video = cv2.VideoCapture('my_video_TPsAV.mp4')\n",
    "\n",
    "# Création des soustracteurs de fond\n",
    "meth_mog2 = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=50)\n",
    "meth_knn = cv2.createBackgroundSubtractorKNN(history=100, dist2Threshold=1000)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Application de la soustraction de fond avec MOG2\n",
    "    mask_mog2 = meth_mog2.apply(frame)\n",
    "\n",
    "    # Application de la soustraction de fond avec KNN\n",
    "    mask_knn = meth_knn.apply(frame)\n",
    "\n",
    "    # Affichage des résultats\n",
    "    cv2.imshow(\"MOG2\", mask_mog2)\n",
    "    cv2.imshow(\"KNN\", mask_knn)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UeNkkuHEBtZT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
